{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/WeiJay/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import coremltools\n",
    "\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.3\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : conv2d_1_input, <keras.engine.topology.InputLayer object at 0x10c7d54a8>\n",
      "1 : conv2d_1, <keras.layers.convolutional.Conv2D object at 0x10c7d54e0>\n",
      "2 : conv2d_1__activation__, <keras.layers.core.Activation object at 0x10c765b70>\n",
      "3 : max_pooling2d_1, <keras.layers.pooling.MaxPooling2D object at 0x10c7d57b8>\n",
      "4 : conv2d_2, <keras.layers.convolutional.Conv2D object at 0x10c7d5ef0>\n",
      "5 : conv2d_2__activation__, <keras.layers.core.Activation object at 0x115c086a0>\n",
      "6 : max_pooling2d_2, <keras.layers.pooling.MaxPooling2D object at 0x10c77f5f8>\n",
      "7 : flatten_1, <keras.layers.core.Flatten object at 0x10c819048>\n",
      "8 : dense_1, <keras.layers.core.Dense object at 0x10c7bc7b8>\n",
      "9 : dense_1__activation__, <keras.layers.core.Activation object at 0x115c08ef0>\n",
      "10 : dense_2, <keras.layers.core.Dense object at 0x10c7f4cc0>\n",
      "11 : dense_2__activation__, <keras.layers.core.Activation object at 0x10c793eb8>\n"
     ]
    }
   ],
   "source": [
    "# test simple mnist model to see whether coremltools work\n",
    "\n",
    "mnist_model = coremltools.converters.keras.convert('keras_mnist_model.h5', \n",
    "                                                   input_names='image (28x28)',\n",
    "                                                   image_input_names='image (28x28)',\n",
    "                                                   output_names=['prediction'],\n",
    "                                                   class_labels=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "\n",
    "mnist_model.author = 'Wei Chieh'\n",
    "mnist_model.license = 'test'\n",
    "mnist_model.short_description = 'Predicts a handwritten digit'\n",
    "\n",
    "mnist_model.save('my_mnist.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/WeiJay/anaconda/lib/python3.6/site-packages/keras/models.py:255: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "/Users/WeiJay/anaconda/lib/python3.6/site-packages/coremltools/converters/keras/_layers2.py:499: RuntimeWarning: invalid value encountered in sqrt\n",
      "  f = 1.0 / _np.sqrt(std + keras_layer.epsilon)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : input_1, <keras.engine.topology.InputLayer object at 0x1138bc668>\n",
      "1 : conv2d_1, <keras.layers.convolutional.Conv2D object at 0x1138bc6d8>\n",
      "2 : batch_normalization_1, <keras.layers.normalization.BatchNormalization object at 0x1138bc978>\n",
      "3 : leaky_re_lu_1, <keras.layers.advanced_activations.LeakyReLU object at 0x1138bca90>\n",
      "4 : max_pooling2d_1, <keras.layers.pooling.MaxPooling2D object at 0x1138bccf8>\n",
      "5 : conv2d_2, <keras.layers.convolutional.Conv2D object at 0x1138bcd30>\n",
      "6 : batch_normalization_2, <keras.layers.normalization.BatchNormalization object at 0x1138bcdd8>\n",
      "7 : leaky_re_lu_2, <keras.layers.advanced_activations.LeakyReLU object at 0x1138bcf60>\n",
      "8 : max_pooling2d_2, <keras.layers.pooling.MaxPooling2D object at 0x113955128>\n",
      "9 : conv2d_3, <keras.layers.convolutional.Conv2D object at 0x1139551d0>\n",
      "10 : batch_normalization_3, <keras.layers.normalization.BatchNormalization object at 0x113955358>\n",
      "11 : leaky_re_lu_3, <keras.layers.advanced_activations.LeakyReLU object at 0x1139554a8>\n",
      "12 : max_pooling2d_3, <keras.layers.pooling.MaxPooling2D object at 0x1139554e0>\n",
      "13 : conv2d_4, <keras.layers.convolutional.Conv2D object at 0x113955588>\n",
      "14 : batch_normalization_4, <keras.layers.normalization.BatchNormalization object at 0x113955710>\n",
      "15 : leaky_re_lu_4, <keras.layers.advanced_activations.LeakyReLU object at 0x113955860>\n",
      "16 : max_pooling2d_4, <keras.layers.pooling.MaxPooling2D object at 0x113955898>\n",
      "17 : conv2d_5, <keras.layers.convolutional.Conv2D object at 0x113955940>\n",
      "18 : batch_normalization_5, <keras.layers.normalization.BatchNormalization object at 0x113955ac8>\n",
      "19 : leaky_re_lu_5, <keras.layers.advanced_activations.LeakyReLU object at 0x113955c18>\n",
      "20 : max_pooling2d_5, <keras.layers.pooling.MaxPooling2D object at 0x113955c50>\n",
      "21 : conv2d_6, <keras.layers.convolutional.Conv2D object at 0x113955cf8>\n",
      "22 : batch_normalization_6, <keras.layers.normalization.BatchNormalization object at 0x113955e80>\n",
      "23 : leaky_re_lu_6, <keras.layers.advanced_activations.LeakyReLU object at 0x1138bcfd0>\n",
      "24 : max_pooling2d_6, <keras.layers.pooling.MaxPooling2D object at 0x11395d048>\n",
      "25 : conv2d_7, <keras.layers.convolutional.Conv2D object at 0x11395d0f0>\n",
      "26 : batch_normalization_7, <keras.layers.normalization.BatchNormalization object at 0x11395d278>\n",
      "27 : leaky_re_lu_7, <keras.layers.advanced_activations.LeakyReLU object at 0x11395d3c8>\n",
      "28 : conv2d_8, <keras.layers.convolutional.Conv2D object at 0x11395d400>\n",
      "29 : batch_normalization_8, <keras.layers.normalization.BatchNormalization object at 0x11395d588>\n",
      "30 : leaky_re_lu_8, <keras.layers.advanced_activations.LeakyReLU object at 0x11395d6d8>\n",
      "31 : conv2d_9, <keras.layers.convolutional.Conv2D object at 0x11395d710>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error compiling model: \"compiler error:  Error saving network to file.\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-503b0156f5d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                                                    \u001b[0mimage_input_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                                    \u001b[0moutput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'grid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                                                    image_scale=1/255.)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0myolo_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Original paper: Joseph Redmon, Ali Farhadi'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/coremltools/converters/keras/_keras_converter.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(model, input_names, output_names, image_input_names, is_bgr, red_bias, green_bias, blue_bias, gray_bias, image_scale, class_labels, predicted_feature_name, model_precision, predicted_probabilities_output, add_custom_layers, custom_conversion_functions)\u001b[0m\n\u001b[1;32m    745\u001b[0m                       custom_conversion_functions=custom_conversion_functions)\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_MLModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/coremltools/models/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmktemp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.mlmodel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0m_save_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__proxy__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_proxy_from_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected model to be a .mlmodel file or a Model_pb2 object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/coremltools/models/model.py\u001b[0m in \u001b[0;36m_get_proxy_from_spec\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_MLModelProxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error compiling model: \"compiler error:  Error saving network to file.\"."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "You can download cfg and weights here: https://pjreddie.com/darknet/yolo/\n",
    "\n",
    "wget http://pjreddie.com/media/files/tiny-yolo.weights\n",
    "wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/tiny-yolo.cfg\n",
    "./yad2k.py tiny-yolo.cfg tiny-yolo-voc.weights model_data/tiny-yolo.h5\n",
    "\"\"\"\n",
    "\n",
    "# Convert tiny-yolo.h5 to CoreML\n",
    "\n",
    "yolo_model = coremltools.converters.keras.convert('tiny-yolo.h5', \n",
    "                                                   input_names='image',\n",
    "                                                   image_input_names='image',\n",
    "                                                   output_names=['grid'],\n",
    "                                                   image_scale=1/255.)\n",
    "\n",
    "yolo_model.author = 'Original paper: Joseph Redmon, Ali Farhadi'\n",
    "yolo_model.license = 'MIT'\n",
    "yolo_model.short_description = 'The Tiny YOLO network from the paper \\'YOLO9000: Better, Faster, Stronger\\' (2016), arXiv:1612.08242'\n",
    "yolo_model.input_description['image'] = 'Input image'\n",
    "yolo_model.output_description['grid'] = 'The 13x13 grid with the bounding box data'\n",
    "\n",
    "yolo_model.save('tiny-yolo.mlmodel')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I test this model and it fails to predict anything\n",
    "\n",
    "\n",
    "```python\n",
    "./test_yolo.py model_data/tiny-yolo.h5 --anchors_path model_data/tiny-yolo_anchors.txt --classes_path model_data/coco_classes.txt\n",
    "\n",
    "\n",
    "Found 0 boxes for dog.jpg\n",
    "Found 0 boxes for scream.jpg\n",
    "Found 0 boxes for eagle.jpg\n",
    "Found 0 boxes for person.jpg\n",
    "Found 0 boxes for giraffe.jpg\n",
    "Found 0 boxes for horses.jpg\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/WeiJay/anaconda/lib/python3.6/site-packages/keras/models.py:255: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : input_1, <keras.engine.topology.InputLayer object at 0x1142c1ef0>\n",
      "1 : conv2d_1, <keras.layers.convolutional.Conv2D object at 0x1142c1f60>\n",
      "2 : batch_normalization_1, <keras.layers.normalization.BatchNormalization object at 0x1142c3278>\n",
      "3 : leaky_re_lu_1, <keras.layers.advanced_activations.LeakyReLU object at 0x1142c3518>\n",
      "4 : max_pooling2d_1, <keras.layers.pooling.MaxPooling2D object at 0x1142c3550>\n",
      "5 : conv2d_2, <keras.layers.convolutional.Conv2D object at 0x1142c35f8>\n",
      "6 : batch_normalization_2, <keras.layers.normalization.BatchNormalization object at 0x1142c3780>\n",
      "7 : leaky_re_lu_2, <keras.layers.advanced_activations.LeakyReLU object at 0x1142c38d0>\n",
      "8 : max_pooling2d_2, <keras.layers.pooling.MaxPooling2D object at 0x1142c3908>\n",
      "9 : conv2d_3, <keras.layers.convolutional.Conv2D object at 0x1142c39b0>\n",
      "10 : batch_normalization_3, <keras.layers.normalization.BatchNormalization object at 0x1142c3b38>\n",
      "11 : leaky_re_lu_3, <keras.layers.advanced_activations.LeakyReLU object at 0x1142c3c88>\n",
      "12 : max_pooling2d_3, <keras.layers.pooling.MaxPooling2D object at 0x1142c3cc0>\n",
      "13 : conv2d_4, <keras.layers.convolutional.Conv2D object at 0x1142c3d68>\n",
      "14 : batch_normalization_4, <keras.layers.normalization.BatchNormalization object at 0x1142c3ef0>\n",
      "15 : leaky_re_lu_4, <keras.layers.advanced_activations.LeakyReLU object at 0x1142c1f98>\n",
      "16 : max_pooling2d_4, <keras.layers.pooling.MaxPooling2D object at 0x1142cb0b8>\n",
      "17 : conv2d_5, <keras.layers.convolutional.Conv2D object at 0x1142cb160>\n",
      "18 : batch_normalization_5, <keras.layers.normalization.BatchNormalization object at 0x1142cb2e8>\n",
      "19 : leaky_re_lu_5, <keras.layers.advanced_activations.LeakyReLU object at 0x1142cb438>\n",
      "20 : max_pooling2d_5, <keras.layers.pooling.MaxPooling2D object at 0x1142cb470>\n",
      "21 : conv2d_6, <keras.layers.convolutional.Conv2D object at 0x1142cb518>\n",
      "22 : batch_normalization_6, <keras.layers.normalization.BatchNormalization object at 0x1142cb6a0>\n",
      "23 : leaky_re_lu_6, <keras.layers.advanced_activations.LeakyReLU object at 0x1142cb7f0>\n",
      "24 : max_pooling2d_6, <keras.layers.pooling.MaxPooling2D object at 0x1142cb828>\n",
      "25 : conv2d_7, <keras.layers.convolutional.Conv2D object at 0x1142cb8d0>\n",
      "26 : batch_normalization_7, <keras.layers.normalization.BatchNormalization object at 0x1142cba58>\n",
      "27 : leaky_re_lu_7, <keras.layers.advanced_activations.LeakyReLU object at 0x1142cbba8>\n",
      "28 : conv2d_8, <keras.layers.convolutional.Conv2D object at 0x1142cbbe0>\n",
      "29 : batch_normalization_8, <keras.layers.normalization.BatchNormalization object at 0x1142cbd68>\n",
      "30 : leaky_re_lu_8, <keras.layers.advanced_activations.LeakyReLU object at 0x1142cbeb8>\n",
      "31 : conv2d_9, <keras.layers.convolutional.Conv2D object at 0x1142cbef0>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In yad2k.py, modify\n",
    "weights_header = np.ndarray(shape=(4, ), dtype='int32', buffer=weights_file.read(16)) \n",
    "to \n",
    "weights_header = np.ndarray(shape=(4, ), dtype='int32', buffer=weights_file.read(20))\n",
    "\n",
    "generate new tiny-yolo20.h5\n",
    "\"\"\"\n",
    "\n",
    "# Convert tiny-yolo.h5 to CoreML\n",
    "\n",
    "yolo_model = coremltools.converters.keras.convert('tiny-yolo20.h5', \n",
    "                                                   input_names='image',\n",
    "                                                   image_input_names='image',\n",
    "                                                   output_names=['grid'],\n",
    "                                                   image_scale=1/255.)\n",
    "\n",
    "yolo_model.author = 'Original paper: Joseph Redmon, Ali Farhadi'\n",
    "yolo_model.license = 'MIT'\n",
    "yolo_model.short_description = 'The Tiny YOLO network from the paper \\'YOLO9000: Better, Faster, Stronger\\' (2016), arXiv:1612.08242'\n",
    "yolo_model.input_description['image'] = 'Input image'\n",
    "yolo_model.output_description['grid'] = 'The 13x13 grid with the bounding box data'\n",
    "\n",
    "yolo_model.save('tiny-yolo20.mlmodel')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also test this model and it works!\n",
    "```\n",
    "./test_yolo.py model_data/tiny-yolo20.h5 --anchors_path model_data/tiny-yolo_anchors.txt --classes_path model_data/coco_classes.txt\n",
    "\n",
    "\n",
    "Found 6 boxes for dog.jpg\n",
    "person 0.34 (66, 66) (97, 94)\n",
    "car 0.40 (500, 101) (716, 176)\n",
    "motorbike 0.44 (64, 78) (100, 120)\n",
    "dog 0.44 (128, 212) (389, 531)\n",
    "car 0.62 (455, 85) (669, 166)\n",
    "bicycle 0.85 (45, 93) (596, 482)\n",
    "Found 0 boxes for scream.jpg\n",
    "Found 1 boxes for eagle.jpg\n",
    "bird 0.87 (57, 127) (608, 465)\n",
    "Found 3 boxes for person.jpg\n",
    "dog 0.66 (66, 258) (203, 349)\n",
    "horse 0.75 (420, 133) (597, 335)\n",
    "person 0.86 (184, 100) (277, 337)\n",
    "Found 2 boxes for giraffe.jpg\n",
    "giraffe 0.62 (145, 0) (445, 416)\n",
    "zebra 0.75 (262, 274) (418, 444)\n",
    "Found 4 boxes for horses.jpg\n",
    "horse 0.46 (224, 187) (437, 374)\n",
    "horse 0.58 (7, 183) (171, 255)\n",
    "horse 0.87 (421, 208) (589, 352)\n",
    "horse 0.87 (9, 187) (292, 400)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
